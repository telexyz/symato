{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GLOMQuyet/symato/blob/main/DataMaker_for_Alpaca_style_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTpJ8axD8j1Z",
        "outputId": "1f1aafd1-c0f2-4330-aee0-9d445c88fd28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wucl58v8Z4M",
        "outputId": "6c52fe40-b267-4268-c797-07d1f81397d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stanford_alpaca'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 103 (delta 0), reused 1 (delta 0), pack-reused 100\u001b[K\n",
            "Receiving objects: 100% (103/103), 9.13 MiB | 10.79 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tatsu-lab/stanford_alpaca.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stanford_alpaca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7GbIimj8-15",
        "outputId": "6e3b9e7d-3647-4fac-c0f3-5eca8d755bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stanford_alpaca\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alpaca Data Creator\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/tatsu-lab/stanford_alpaca/blob/main/assets/parse_analysis.png?raw=1\" alt=\"example image\" width=\"600\">"
      ],
      "metadata": {
        "id": "tibz9rzb9mKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fLiaceig9A8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "869c27f9-52f6-42da-bf29-e9efdd65c007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.22.4)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (0.27.2)\n",
            "Collecting transformers>=4.26.1\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (1.13.1+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.12.1\n",
            "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score->-r requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->-r requirements.txt (line 3)) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai->-r requirements.txt (line 4)) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai->-r requirements.txt (line 4)) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai->-r requirements.txt (line 4)) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->-r requirements.txt (line 5)) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->-r requirements.txt (line 5)) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->-r requirements.txt (line 5)) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.26.1->-r requirements.txt (line 5)) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->-r requirements.txt (line 6)) (4.5.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 9)) (3.19.6)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 9)) (67.6.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 9)) (8.1.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 9)) (5.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 9)) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai->-r requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score->-r requirements.txt (line 2)) (1.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: rouge_score, fire, pathtools\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=b7c1b74af231aac00622b417e622cda951b0705c33e7e7da81151343cdfb5d1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=bb7b2a4584982a57acf88040b7b7bcf4fda7428f5f4c6d8d3a5b86b55fa8ca88\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=39ea7ba887c8c62fc23ffbb67c1834657149f22af6a15de83dbc375438441138\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built rouge_score fire pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, pathtools, smmap, setproctitle, sentry-sdk, fire, docker-pycreds, rouge_score, huggingface-hub, gitdb, transformers, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 fire-0.5.0 gitdb-4.0.10 huggingface-hub-0.13.3 pathtools-0.1.2 rouge_score-0.1.2 sentencepiece-0.1.97 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.12.1 transformers-4.27.3 wandb-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVv_dDCTW1E5",
        "outputId": "8905dce5-4e83-4311-e6d4-fa25813bd324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key =''\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "M5b0ALlsp8Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generations"
      ],
      "metadata": {
        "id": "SGbDrUbi_JJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from rouge_score import rouge_scorer\n",
        "import utils\n",
        "\n",
        "import fire"
      ],
      "metadata": {
        "id": "qefoyuTtBjkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_prompt(prompt_instructions):\n",
        "    \"\"\"Encode multiple prompt instructions into a single string.\"\"\"\n",
        "    prompt = open(\"./prompt.txt\").read() + \"\\n\"\n",
        "\n",
        "    for idx, task_dict in enumerate(prompt_instructions):\n",
        "        (instruction, input, output) = task_dict[\"instruction\"], task_dict[\"input\"], task_dict[\"output\"]\n",
        "        instruction = re.sub(r\"\\s+\", \" \", instruction).strip().rstrip(\":\")\n",
        "        input = \"<noinput>\" if input.lower() == \"\" else input\n",
        "        prompt += f\"###\\n\"\n",
        "        prompt += f\"{idx + 1}. Instruction: {instruction}\\n\"\n",
        "        prompt += f\"{idx + 1}. Input:\\n{input}\\n\"\n",
        "        prompt += f\"{idx + 1}. Output:\\n{output}\\n\"\n",
        "    prompt += f\"###\\n\"\n",
        "    prompt += f\"{idx + 2}. Instruction:\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def post_process_gpt3_response(num_prompt_instructions, response):\n",
        "    if response is None:\n",
        "        return []\n",
        "    raw_instructions = f\"{num_prompt_instructions+1}. Instruction:\" + response[\"text\"]\n",
        "    raw_instructions = re.split(\"###\", raw_instructions)\n",
        "    instructions = []\n",
        "    for idx, inst in enumerate(raw_instructions):\n",
        "        # if the decoding stops due to length, the last example is likely truncated so we discard it\n",
        "        if idx == len(raw_instructions) - 1 and response[\"finish_reason\"] == \"length\":\n",
        "            continue\n",
        "        idx += num_prompt_instructions + 1\n",
        "        splitted_data = re.split(f\"{idx}\\.\\s+(Instruction|Input|Output):\", inst)\n",
        "        if len(splitted_data) != 7:\n",
        "            continue\n",
        "        else:\n",
        "            inst = splitted_data[2].strip()\n",
        "            input = splitted_data[4].strip()\n",
        "            input = \"\" if input.lower() == \"<noinput>\" else input\n",
        "            output = splitted_data[6].strip()\n",
        "        # filter out too short or too long instructions\n",
        "        if len(inst.split()) <= 3 or len(inst.split()) > 150:\n",
        "            continue\n",
        "        # filter based on keywords that are not suitable for language models.\n",
        "        blacklist = [\n",
        "            \"image\",\n",
        "            \"images\",\n",
        "            \"graph\",\n",
        "            \"graphs\",\n",
        "            \"picture\",\n",
        "            \"pictures\",\n",
        "            \"file\",\n",
        "            \"files\",\n",
        "            \"map\",\n",
        "            \"maps\",\n",
        "            \"draw\",\n",
        "            \"plot\",\n",
        "            \"go to\",\n",
        "            \"video\",\n",
        "            \"audio\",\n",
        "            \"music\",\n",
        "            \"flowchart\",\n",
        "            \"diagram\",\n",
        "        ]\n",
        "        blacklist += []\n",
        "        if any(find_word_in_string(word, inst) for word in blacklist):\n",
        "            continue\n",
        "        # We found that the model tends to add \"write a program\" to some existing instructions, which lead to a lot of such instructions.\n",
        "        # And it's a bit comfusing whether the model need to write a program or directly output the result.\n",
        "        # Here we filter them out.\n",
        "        # Note this is not a comprehensive filtering for all programming instructions.\n",
        "        if inst.startswith(\"Write a program\"):\n",
        "            continue\n",
        "        # filter those starting with punctuation\n",
        "        if inst[0] in string.punctuation:\n",
        "            continue\n",
        "        # filter those starting with non-english character\n",
        "        if not inst[0].isascii():\n",
        "            continue\n",
        "        instructions.append({\"instruction\": inst, \"input\": input, \"output\": output})\n",
        "    return instructions\n",
        "\n",
        "\n",
        "def find_word_in_string(w, s):\n",
        "    return re.compile(r\"\\b({0})\\b\".format(w), flags=re.IGNORECASE).search(s)\n",
        "\n",
        "\n",
        "def generate_instruction_following_data(\n",
        "    output_dir=\"./\",\n",
        "    seed_tasks_path=\"./seed_tasks.jsonl\",\n",
        "    num_instructions_to_generate=10,\n",
        "    model_name=\"text-davinci-003\",\n",
        "    num_prompt_instructions=3,\n",
        "    request_batch_size=5,\n",
        "    temperature=1.0,\n",
        "    top_p=1.0,\n",
        "    num_cpus=16,\n",
        "):\n",
        "    seed_tasks = [json.loads(l) for l in open(seed_tasks_path, \"r\")]\n",
        "    seed_instruction_data = [\n",
        "        {\"instruction\": t[\"instruction\"], \"input\": t[\"instances\"][0][\"input\"], \"output\": t[\"instances\"][0][\"output\"]}\n",
        "        for t in seed_tasks\n",
        "    ]\n",
        "    print(f\"Loaded {len(seed_instruction_data)} human-written seed instructions\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    request_idx = 0\n",
        "    # load the LM-generated instructions\n",
        "    machine_instruction_data = []\n",
        "    if os.path.exists(os.path.join(output_dir, \"regen.json\")):\n",
        "        machine_instruction_data = utils.jload(os.path.join(output_dir, \"regen.json\"))\n",
        "        print(f\"Loaded {len(machine_instruction_data)} machine-generated instructions\")\n",
        "\n",
        "    # similarities = {}\n",
        "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=False)\n",
        "\n",
        "    # now let's generate new instructions!\n",
        "    progress_bar = tqdm.tqdm(total=num_instructions_to_generate)\n",
        "    if machine_instruction_data:\n",
        "        progress_bar.update(len(machine_instruction_data))\n",
        "\n",
        "    # first we tokenize all the seed instructions and generated machine instructions\n",
        "    all_instructions = [d[\"instruction\"] for d in seed_instruction_data] + [\n",
        "        d[\"instruction\"] for d in machine_instruction_data\n",
        "    ]\n",
        "    all_instruction_tokens = [scorer._tokenizer.tokenize(inst) for inst in all_instructions]\n",
        "\n",
        "    while len(machine_instruction_data) < num_instructions_to_generate:\n",
        "        request_idx += 1\n",
        "\n",
        "        batch_inputs = []\n",
        "        for _ in range(request_batch_size):\n",
        "            # only sampling from the seed tasks\n",
        "            prompt_instructions = random.sample(seed_instruction_data, num_prompt_instructions)\n",
        "            prompt = encode_prompt(prompt_instructions)\n",
        "            batch_inputs.append(prompt)\n",
        "        decoding_args = utils.OpenAIDecodingArguments(\n",
        "            temperature=temperature,\n",
        "            n=1,\n",
        "            max_tokens=3072,  # hard-code to maximize the length. the requests will be automatically adjusted\n",
        "            top_p=top_p,\n",
        "            stop=[\"\\n20\", \"20.\", \"20.\"],\n",
        "        )\n",
        "        request_start = time.time()\n",
        "        results = utils.openai_completion(\n",
        "            prompts=batch_inputs,\n",
        "            model_name=model_name,\n",
        "            batch_size=request_batch_size,\n",
        "            decoding_args=decoding_args,\n",
        "            logit_bias={\"50256\": -100},  # prevent the <|endoftext|> token from being generated\n",
        "        )\n",
        "        request_duration = time.time() - request_start\n",
        "\n",
        "        process_start = time.time()\n",
        "        instruction_data = []\n",
        "        for result in results:\n",
        "            new_instructions = post_process_gpt3_response(num_prompt_instructions, result)\n",
        "            instruction_data += new_instructions\n",
        "\n",
        "        total = len(instruction_data)\n",
        "        keep = 0\n",
        "        for instruction_data_entry in instruction_data:\n",
        "            # computing similarity with the pre-tokenzied instructions\n",
        "            new_instruction_tokens = scorer._tokenizer.tokenize(instruction_data_entry[\"instruction\"])\n",
        "            with Pool(num_cpus) as p:\n",
        "                rouge_scores = p.map(\n",
        "                    partial(rouge_scorer._score_lcs, new_instruction_tokens),\n",
        "                    all_instruction_tokens,\n",
        "                )\n",
        "            rouge_scores = [score.fmeasure for score in rouge_scores]\n",
        "            most_similar_instructions = {\n",
        "                all_instructions[i]: rouge_scores[i] for i in np.argsort(rouge_scores)[-10:][::-1]\n",
        "            }\n",
        "            if max(rouge_scores) > 0.7:\n",
        "                continue\n",
        "            else:\n",
        "                keep += 1\n",
        "            instruction_data_entry[\"most_similar_instructions\"] = most_similar_instructions\n",
        "            instruction_data_entry[\"avg_similarity_score\"] = float(np.mean(rouge_scores))\n",
        "            machine_instruction_data.append(instruction_data_entry)\n",
        "            all_instructions.append(instruction_data_entry[\"instruction\"])\n",
        "            all_instruction_tokens.append(new_instruction_tokens)\n",
        "            progress_bar.update(1)\n",
        "        process_duration = time.time() - process_start\n",
        "        print(f\"Request {request_idx} took {request_duration:.2f}s, processing took {process_duration:.2f}s\")\n",
        "        print(f\"Generated {total} instructions, kept {keep} instructions\")\n",
        "        utils.jdump(machine_instruction_data, os.path.join(output_dir, \"regen.json\"))\n"
      ],
      "metadata": {
        "id": "JlvGPSJK_cT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the data"
      ],
      "metadata": {
        "id": "eDzyIc89ENYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_new_tasks = '''\n",
        "[\n",
        "    {\n",
        "        \"id\": \"new_seed_task_3\",\n",
        "        \"name\": \"lựa chọn bữa tối chay\",\n",
        "        \"instruction\": \"Một số lựa chọn bữa tối chay có hàm lượng protein cao là gì?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Một số lựa chọn bữa tối chay có hàm lượng protein cao bao gồm súp đậu lăng, cà ri đậu xanh, đậu phụ xào, tacos tempeh và ớt nhồi quinoa.\"}],\n",
        "        \"is_classification\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"new_seed_task_4\",\n",
        "        \"name\": \"giải thích chính sách hoàn trả\",\n",
        "        \"instruction\": \"Can you explain your refund policy?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Our refund policy allows customers to request a refund within 30 days of purchase if they are unsatisfied with the product or service. To be eligible for a refund, the product must be in its original condition and packaging, and services must not have been completed.\"}],\n",
        "        \"is_classification\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"new_seed_task_5\",\n",
        "        \"name\": \"khắc phục sự cố kết nối wifi\",\n",
        "        \"instruction\": \"Tôi đang gặp sự cố khi kết nối với mạng Wi-Fi của mình. Tôi nên làm gì?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Trước tiên, hãy kiểm tra xem thiết bị của bạn có nằm trong phạm vi phủ sóng của bộ định tuyến Wi-Fi không. Sau đó, xác minh rằng bạn đã nhập đúng tên mạng và mật khẩu. Nếu sự cố vẫn tiếp diễn, hãy thử khởi động lại cả thiết bị và bộ định tuyến của bạn. Nếu bạn vẫn không thể kết nối, hãy liên hệ với nhà cung cấp dịch vụ internet của bạn để được hỗ trợ thêm.\"}],\n",
        "        \"is_classification\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"new_seed_task_6\",\n",
        "        \"name\": \"hướng dẫn thay đổi mật khẩu\",\n",
        "        \"instruction\": \"Làm thế nào để thay đổi mật khẩu của tôi?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Để thay đổi mật khẩu của bạn, hãy đăng nhập vào tài khoản của bạn, đi tới phần cài đặt hoặc quản lý tài khoản và tìm tùy chọn thay đổi mật khẩu của bạn. Nhập mật khẩu hiện tại của bạn, sau đó nhập mật khẩu mới của bạn hai lần để xác nhận. Lưu các thay đổi của bạn để cập nhật mật khẩu của bạn.\"}],\n",
        "        \"is_classification\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"new_seed_task_7\",\n",
        "        \"name\": \"yêu cầu gói bị mất\",\n",
        "        \"instruction\": \"Gói hàng của tôi vẫn chưa đến. Tôi nên làm gì?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Trước tiên, hãy kiểm tra email hoặc tài khoản xác nhận đơn đặt hàng của bạn để biết số theo dõi và ước tính ngày giao hàng. Nếu đã qua ngày giao hàng, hãy liên hệ với hãng vận chuyển kèm theo số theo dõi của bạn để cập nhật. Nếu nhà cung cấp dịch vụ không thể giải quyết vấn đề, vui lòng liên hệ với nhóm hỗ trợ khách hàng của chúng tôi để được hỗ trợ.\"}],\n",
        "        \"is_classification\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"new_seed_task_8\",\n",
        "        \"name\": \"thay đổi thứ tự\",\n",
        "        \"instruction\": \"Tôi cần sửa đổi đơn đặt hàng của mình. Làm thế nào tôi có thể làm điều đó?\",\n",
        "        \"instances\": [{\"input\": \"\",\n",
        "                      \"output\": \"Để sửa đổi đơn đặt hàng của bạn, vui lòng liên hệ với nhóm hỗ trợ khách hàng của chúng tôi càng sớm càng tốt với số đơn đặt hàng của bạn và những thay đổi bạn muốn thực hiện. Xin lưu ý rằng có thể không sửa đổi được nếu đơn đặt hàng đã được xử lý hoặc vận chuyển.\"}],\n",
        "        \"is_classification\": false\n",
        "    }\n",
        "]\n",
        "'''\n"
      ],
      "metadata": {
        "id": "MiiKwelz6GCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_seed_tasks = json.loads(json_new_tasks)\n",
        "print(new_seed_tasks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MysTLv3y-gLa",
        "outputId": "4f1531ac-f76e-41fb-b970-6ba8742eafb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 'new_seed_task_3', 'name': 'lựa chọn bữa tối chay', 'instruction': 'Một số lựa chọn bữa tối chay có hàm lượng protein cao là gì?', 'instances': [{'input': '', 'output': 'Một số lựa chọn bữa tối chay có hàm lượng protein cao bao gồm súp đậu lăng, cà ri đậu xanh, đậu phụ xào, tacos tempeh và ớt nhồi quinoa.'}], 'is_classification': False}, {'id': 'new_seed_task_4', 'name': 'giải thích chính sách hoàn trả', 'instruction': 'Can you explain your refund policy?', 'instances': [{'input': '', 'output': 'Our refund policy allows customers to request a refund within 30 days of purchase if they are unsatisfied with the product or service. To be eligible for a refund, the product must be in its original condition and packaging, and services must not have been completed.'}], 'is_classification': False}, {'id': 'new_seed_task_5', 'name': 'khắc phục sự cố kết nối wifi', 'instruction': 'Tôi đang gặp sự cố khi kết nối với mạng Wi-Fi của mình. Tôi nên làm gì?', 'instances': [{'input': '', 'output': 'Trước tiên, hãy kiểm tra xem thiết bị của bạn có nằm trong phạm vi phủ sóng của bộ định tuyến Wi-Fi không. Sau đó, xác minh rằng bạn đã nhập đúng tên mạng và mật khẩu. Nếu sự cố vẫn tiếp diễn, hãy thử khởi động lại cả thiết bị và bộ định tuyến của bạn. Nếu bạn vẫn không thể kết nối, hãy liên hệ với nhà cung cấp dịch vụ internet của bạn để được hỗ trợ thêm.'}], 'is_classification': False}, {'id': 'new_seed_task_6', 'name': 'hướng dẫn thay đổi mật khẩu', 'instruction': 'Làm thế nào để thay đổi mật khẩu của tôi?', 'instances': [{'input': '', 'output': 'Để thay đổi mật khẩu của bạn, hãy đăng nhập vào tài khoản của bạn, đi tới phần cài đặt hoặc quản lý tài khoản và tìm tùy chọn thay đổi mật khẩu của bạn. Nhập mật khẩu hiện tại của bạn, sau đó nhập mật khẩu mới của bạn hai lần để xác nhận. Lưu các thay đổi của bạn để cập nhật mật khẩu của bạn.'}], 'is_classification': False}, {'id': 'new_seed_task_7', 'name': 'yêu cầu gói bị mất', 'instruction': 'Gói hàng của tôi vẫn chưa đến. Tôi nên làm gì?', 'instances': [{'input': '', 'output': 'Trước tiên, hãy kiểm tra email hoặc tài khoản xác nhận đơn đặt hàng của bạn để biết số theo dõi và ước tính ngày giao hàng. Nếu đã qua ngày giao hàng, hãy liên hệ với hãng vận chuyển kèm theo số theo dõi của bạn để cập nhật. Nếu nhà cung cấp dịch vụ không thể giải quyết vấn đề, vui lòng liên hệ với nhóm hỗ trợ khách hàng của chúng tôi để được hỗ trợ.'}], 'is_classification': False}, {'id': 'new_seed_task_8', 'name': 'thay đổi thứ tự', 'instruction': 'Tôi cần sửa đổi đơn đặt hàng của mình. Làm thế nào tôi có thể làm điều đó?', 'instances': [{'input': '', 'output': 'Để sửa đổi đơn đặt hàng của bạn, vui lòng liên hệ với nhóm hỗ trợ khách hàng của chúng tôi càng sớm càng tốt với số đơn đặt hàng của bạn và những thay đổi bạn muốn thực hiện. Xin lưu ý rằng có thể không sửa đổi được nếu đơn đặt hàng đã được xử lý hoặc vận chuyển.'}], 'is_classification': False}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('new_seed_tasks.jsonl', 'w') as outfile:\n",
        "    for task_dict in new_seed_tasks:\n",
        "        json.dump(task_dict, outfile)\n",
        "        outfile.write('\\n')"
      ],
      "metadata": {
        "id": "GMs7BWWa-v1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir new_tasks"
      ],
      "metadata": {
        "id": "7EslAAQqBGYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_instruction_following_data(\n",
        "    output_dir=\"./new_tasks/\",\n",
        "    seed_tasks_path=\"./new_seed_tasks.jsonl\",\n",
        "    num_instructions_to_generate=5,\n",
        "    model_name=\"text-davinci-003\",\n",
        "    num_prompt_instructions=3,\n",
        "    request_batch_size=2,\n",
        "    temperature=1.0,\n",
        "    top_p=1.0,\n",
        "    num_cpus=4,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PitLnTF6Aznv",
        "outputId": "3c45e688-f497-4510-a11c-755ffe7e0c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 6 human-written seed instructions\n",
            "Loaded 0 machine-generated instructions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/5 [05:11<?, ?it/s]\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 5563 tokens (2491 in your prompt; 3072 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 2457, Retrying...\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 4948 tokens (2491 in your prompt; 2457 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 1965, Retrying...\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 4456 tokens (2491 in your prompt; 1965 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 1572, Retrying...\n",
            "\n",
            "\n",
            "\n",
            "prompt_batches: 100%|██████████| 1/1 [00:35<00:00, 35.70s/it]\n",
            "\n",
            "\n",
            " 20%|██        | 1/5 [00:35<02:23, 35.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60%|██████    | 3/5 [00:35<00:18,  9.32s/it]\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request 1 took 35.71s, processing took 0.25s\n",
            "Generated 4 instructions, kept 4 instructions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rprompt_batches:   0%|          | 0/1 [00:00<?, ?it/s]WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 5315 tokens (2243 in your prompt; 3072 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 2457, Retrying...\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 4700 tokens (2243 in your prompt; 2457 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 1965, Retrying...\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 4208 tokens (2243 in your prompt; 1965 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 1572, Retrying...\n",
            "WARNING:root:OpenAIError: This model's maximum context length is 4097 tokens, however you requested 4164 tokens (2592 in your prompt; 1572 for the completion). Please reduce your prompt; or completion length..\n",
            "WARNING:root:Reducing target length to 1257, Retrying...\n",
            "\n",
            "\n",
            "prompt_batches: 100%|██████████| 1/1 [00:28<00:00, 28.63s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 5/5 [01:04<00:00, 11.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "8it [01:04,  5.70s/it]                       \u001b[A\u001b[A\n",
            "\n",
            "10it [01:04,  6.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request 2 took 28.63s, processing took 0.32s\n",
            "Generated 6 instructions, kept 6 instructions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = \"/content/stanford_alpaca_vietnamese/new_tasks/regen.json\"\n",
        "\n",
        "with open(file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# drop the most similar as measured by Rouge\n",
        "for dictionary in data:\n",
        "    dictionary.pop('most_similar_instructions', None)\n",
        "    dictionary.pop('avg_similarity_score',None)\n",
        "\n",
        "\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps-91LWXBXt5",
        "outputId": "ec22f200-6a29-4c3c-8a41-511d5aa7ec2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'instruction': 'Tôi cần biết thêm về ứng dụng của chúng ta. Tôi nên làm gì?', 'input': '', 'output': 'Hãy truy cập trang web của chúng tôi để xem thêm thông tin về ứng dụng của chúng tôi. Bạn cũng có thể tham khảo những tài liệu hướng dẫn và hướng dẫn sử dụng ứng dụng của chúng tôi để biết thêm thông tin. Bạn cũng có thể xem thêm các video hướng dẫn về cách sử dụng tính năng và công cụ của ứng dụng của chúng tôi. Nếu bạn cần thêm trợ giúp, vui lòng liên hệ với dịch vụ hỗ trợ khách hàng của chúng tôi để được hỗ trợ.'}, {'instruction': 'Tôi muốn biết cách đặt một cuộc hẹn. Tôi nên làm gì?', 'input': '', 'output': 'Để đặt một cuộc hẹn, hãy tìm kiếm qua trang web của chúng tôi hoặc gọi điện vàoở địa chỉ mà chúng tôi cung cấp. Nếu bạn muốn tự đặt lịch hẹn trên trang web của chúng tôi, hãy chọn ngày và giờ mà bạn muốn dịch vụ và điền vào các thông tin cần thiết. Sau khi hoàn thành đặt hẹn, hãy nhận được một email xác nhận hoặc một số điện thoại để xác nhận cuộc hẹn của bạn.'}, {'instruction': 'Làm thế nào để thay đổi thông tin đăng nhập của tôi?', 'input': '', 'output': \"Bạn có thể thay đổi thông tin đăng nhập của mình bằng cách truy cập trang thiết lập tài khoản của bạn và chỉnh sửa thông tin của mình. Bạn cũng có thể thay đổi mật khẩu của mình bằng cách truy cập vào trang 'Cài đặt bảo mật' trong tài khoản của mình và thực hiện theo các bước hướng dẫn.\\n\\nNếu bạn cần thêm hỗ trợ, hãy liên hệ với dịch vụ hỗ trợ khách hàng của chúng tôi bằng cách gọi điện hoặc chat trực tuyến.\"}, {'instruction': 'Những người trên 45 tuổi nên thực hiện thêm một lối sống sức khỏe?', 'input': '', 'output': 'Những người trên 45 tuổi nên thực hiện những lối sống sức khỏe hàng ngày như bữa ăn uyển chỉnh, ăn nhiều hoa quả và rau củ, giảm béo, luyện tập, điều trị bệnh tật causvà chăm sóc tâm lí tốt. Nếu gia đình có thể, hãy tham gia các hoạt động xã hội, đam mê hoặc tham gia các buổi thể dục để giữ cho tâm thần của bạn sẵn sàng.'}, {'instruction': 'Chạy trong một thời gian dài là gì?', 'input': '', 'output': 'Chạy trong một thời gian dài là cách thức chạy mỗi lần để đi hết chiều dài. Một thời gian dài có thể từ 5 - 10 km hoặc nhiều hơn nếu bạn là một chạy giỏi.'}, {'instruction': 'Bạn cần phải làm gì để cập nhật âm thanh?', 'input': '', 'output': 'Để cập nhật âm thanh, bạn cần một loại thiết bị âm thanh như loa máy tính, loa laptop hoặc loa di động. Bạn cũng cần phải kiểm tra phần mềm cập nhật âm thanh có sẵn trên thiết bị của bạn. Sau đó, bạn cần phải cài đặt phần mềm và sau đó thiết lập lại âm thanh phù hợp với thiết bị bạn sử dụng.'}, {'instruction': 'Bạn có thể hướng dẫn tôi cách gửi một email?', 'input': '', 'output': 'Để gửi một email, đầu tiên bạn cần đăng nhập vào tài khoản email của mình. Sau đó, bạn có thể nhập địa chỉ email người nhận vào phần địa chỉ email. Bạn cũng có thể tùy chỉnh chủ đề và nội dung tin nhắn trước khi gửi email. Sau đó, bạn cần nhấn nút gửi để hoàn thành quá trình gửi email.'}, {'instruction': 'Tôi nên giữ những gì trong kho vận?', 'input': '', 'output': 'Trong kho vận, bạn nên giữ một số đặc trưng như bảng kho hàng, hàng tồn kho, hàng tồn đã đặt trước, hàng hóa kéo dài và hàng dự trữ. Bạn cũng nên giữ những nguyên vật liệu để hỗ trợ việc sản xuất như vật liệu nền tảng, dây điện, keo hợp kim, màng poly và vật liệu bao bì.'}, {'instruction': 'Khi tôi sử dụng ứng dụng đọc tin của tôi, nó hiển thị bài viết không đủ thông tin. Làm thế nào để xem tất cả các bài viết đó?', 'input': '', 'output': 'Ứng dụng đọc tin của bạn có thể đã xác định rằng bài viên của bạn là nóng hoặc nổi bật nhất trên trang chủ của họ. Để xem tất cả các bài viết, hãy vào bộ lọc trên trang chủ của ứng dụng và lựa chọn tất cả từ bộ lọc thời gian. Điều này sẽ cho phép bạn xem tất cả các bài viết mới nhất trên trang web được liệt kê theo ngày.'}, {'instruction': 'Hằng ngày, tôi muốn tạo ra các lời thật về môi trường. Những gì tôi có thể làm?', 'input': '', 'output': 'Có rất nhiều cách để bạn có thể tạo ra các lời thật về môi trường. Hãy tổ chức hoặc dự tham gia các hoạt động, sự kiện các hiệp hội môi trường. Bạn cũng có thể tham gia hoặc hỗ trợ các hoạt động của các tổ chức tự nguyện hoặc các tổ chức toàn cầu đã kết hợp nhau để nâng cao nhận thức xung quanh về môi trường. Bạn cũng có thể hỗ trợ từ xa thông qua việc dành thời gian của mình để làm một số nhiệm vụ như ngôn ngữ của cộng đồng, dịch vụ tuyên truyền, thu thập tài trợ và cống hiến. Bạn cũng có thể tự học về môi trường bằng cách đọc những nguồn thông tin giúp bạn hiểu rõ hơn về những gì đang diễn ra trên thế giới và các phương tiện để bạn có thể hỗ trợ các nhiệm vụ cộng đồng có tính môi trường.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W65CWwCoC4WS",
        "outputId": "1eaef08d-5fc0-4807-cc46-0950656a91d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(data[i])"
      ],
      "metadata": {
        "id": "OwDfCOeAW8sg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a1c81c-ce75-4eea-b0c5-d9ca8bbb4689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Tôi cần biết thêm về ứng dụng của chúng ta. Tôi nên làm gì?', 'input': '', 'output': 'Hãy truy cập trang web của chúng tôi để xem thêm thông tin về ứng dụng của chúng tôi. Bạn cũng có thể tham khảo những tài liệu hướng dẫn và hướng dẫn sử dụng ứng dụng của chúng tôi để biết thêm thông tin. Bạn cũng có thể xem thêm các video hướng dẫn về cách sử dụng tính năng và công cụ của ứng dụng của chúng tôi. Nếu bạn cần thêm trợ giúp, vui lòng liên hệ với dịch vụ hỗ trợ khách hàng của chúng tôi để được hỗ trợ.'}\n",
            "{'instruction': 'Tôi muốn biết cách đặt một cuộc hẹn. Tôi nên làm gì?', 'input': '', 'output': 'Để đặt một cuộc hẹn, hãy tìm kiếm qua trang web của chúng tôi hoặc gọi điện vàoở địa chỉ mà chúng tôi cung cấp. Nếu bạn muốn tự đặt lịch hẹn trên trang web của chúng tôi, hãy chọn ngày và giờ mà bạn muốn dịch vụ và điền vào các thông tin cần thiết. Sau khi hoàn thành đặt hẹn, hãy nhận được một email xác nhận hoặc một số điện thoại để xác nhận cuộc hẹn của bạn.'}\n",
            "{'instruction': 'Làm thế nào để thay đổi thông tin đăng nhập của tôi?', 'input': '', 'output': \"Bạn có thể thay đổi thông tin đăng nhập của mình bằng cách truy cập trang thiết lập tài khoản của bạn và chỉnh sửa thông tin của mình. Bạn cũng có thể thay đổi mật khẩu của mình bằng cách truy cập vào trang 'Cài đặt bảo mật' trong tài khoản của mình và thực hiện theo các bước hướng dẫn.\\n\\nNếu bạn cần thêm hỗ trợ, hãy liên hệ với dịch vụ hỗ trợ khách hàng của chúng tôi bằng cách gọi điện hoặc chat trực tuyến.\"}\n",
            "{'instruction': 'Những người trên 45 tuổi nên thực hiện thêm một lối sống sức khỏe?', 'input': '', 'output': 'Những người trên 45 tuổi nên thực hiện những lối sống sức khỏe hàng ngày như bữa ăn uyển chỉnh, ăn nhiều hoa quả và rau củ, giảm béo, luyện tập, điều trị bệnh tật causvà chăm sóc tâm lí tốt. Nếu gia đình có thể, hãy tham gia các hoạt động xã hội, đam mê hoặc tham gia các buổi thể dục để giữ cho tâm thần của bạn sẵn sàng.'}\n",
            "{'instruction': 'Chạy trong một thời gian dài là gì?', 'input': '', 'output': 'Chạy trong một thời gian dài là cách thức chạy mỗi lần để đi hết chiều dài. Một thời gian dài có thể từ 5 - 10 km hoặc nhiều hơn nếu bạn là một chạy giỏi.'}\n",
            "{'instruction': 'Bạn cần phải làm gì để cập nhật âm thanh?', 'input': '', 'output': 'Để cập nhật âm thanh, bạn cần một loại thiết bị âm thanh như loa máy tính, loa laptop hoặc loa di động. Bạn cũng cần phải kiểm tra phần mềm cập nhật âm thanh có sẵn trên thiết bị của bạn. Sau đó, bạn cần phải cài đặt phần mềm và sau đó thiết lập lại âm thanh phù hợp với thiết bị bạn sử dụng.'}\n",
            "{'instruction': 'Bạn có thể hướng dẫn tôi cách gửi một email?', 'input': '', 'output': 'Để gửi một email, đầu tiên bạn cần đăng nhập vào tài khoản email của mình. Sau đó, bạn có thể nhập địa chỉ email người nhận vào phần địa chỉ email. Bạn cũng có thể tùy chỉnh chủ đề và nội dung tin nhắn trước khi gửi email. Sau đó, bạn cần nhấn nút gửi để hoàn thành quá trình gửi email.'}\n",
            "{'instruction': 'Tôi nên giữ những gì trong kho vận?', 'input': '', 'output': 'Trong kho vận, bạn nên giữ một số đặc trưng như bảng kho hàng, hàng tồn kho, hàng tồn đã đặt trước, hàng hóa kéo dài và hàng dự trữ. Bạn cũng nên giữ những nguyên vật liệu để hỗ trợ việc sản xuất như vật liệu nền tảng, dây điện, keo hợp kim, màng poly và vật liệu bao bì.'}\n",
            "{'instruction': 'Khi tôi sử dụng ứng dụng đọc tin của tôi, nó hiển thị bài viết không đủ thông tin. Làm thế nào để xem tất cả các bài viết đó?', 'input': '', 'output': 'Ứng dụng đọc tin của bạn có thể đã xác định rằng bài viên của bạn là nóng hoặc nổi bật nhất trên trang chủ của họ. Để xem tất cả các bài viết, hãy vào bộ lọc trên trang chủ của ứng dụng và lựa chọn tất cả từ bộ lọc thời gian. Điều này sẽ cho phép bạn xem tất cả các bài viết mới nhất trên trang web được liệt kê theo ngày.'}\n",
            "{'instruction': 'Hằng ngày, tôi muốn tạo ra các lời thật về môi trường. Những gì tôi có thể làm?', 'input': '', 'output': 'Có rất nhiều cách để bạn có thể tạo ra các lời thật về môi trường. Hãy tổ chức hoặc dự tham gia các hoạt động, sự kiện các hiệp hội môi trường. Bạn cũng có thể tham gia hoặc hỗ trợ các hoạt động của các tổ chức tự nguyện hoặc các tổ chức toàn cầu đã kết hợp nhau để nâng cao nhận thức xung quanh về môi trường. Bạn cũng có thể hỗ trợ từ xa thông qua việc dành thời gian của mình để làm một số nhiệm vụ như ngôn ngữ của cộng đồng, dịch vụ tuyên truyền, thu thập tài trợ và cống hiến. Bạn cũng có thể tự học về môi trường bằng cách đọc những nguồn thông tin giúp bạn hiểu rõ hơn về những gì đang diễn ra trên thế giới và các phương tiện để bạn có thể hỗ trợ các nhiệm vụ cộng đồng có tính môi trường.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJX7m9wRZD4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}